{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41c26c9",
   "metadata": {},
   "source": [
    "# Sevendi Eldrige Rifki PoluanðŸ”¥ðŸ”¥ðŸ”¥\n",
    "### Descriptions: Time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eeeffcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 10 17:32:51 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:65:00.0 Off |                  N/A |\n",
      "|  0%   43C    P8               38W / 390W|    225MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# working environment\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b68208",
   "metadata": {},
   "source": [
    "## <font color='red'>Import the necessary libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff4a9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:32:54.282631: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-10 17:32:54.320216: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  \n",
    "import time \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce022c8",
   "metadata": {},
   "source": [
    "## <font color='red'>For this experiment, I will be conducting basic time series forecasting on EUR_USD data from the forex market, covering the period from 2005 to 2020. The dataset was obtained from [Kaggle](https://www.kaggle.com/datasets/imetomi/eur-usd-forex-pair-historical-data-2002-2019?resource=download), where you can also access and download the dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cb4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOREX_EUR_USD_prediction.ipynb\tarchive.zip\t eurusd_minute.csv\r\n",
      "README.md\t\t\teurusd_hour.csv  eurusd_news.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e763c09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  archive.zip\n",
      "  inflating: eurusd_hour.csv         \n",
      "  inflating: eurusd_minute.csv       \n",
      "  inflating: eurusd_news.csv         \n"
     ]
    }
   ],
   "source": [
    "!unzip -o archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22db97de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOREX_EUR_USD_prediction.ipynb\teurusd_hour.csv    eurusd_news.csv\r\n",
      "archive.zip\t\t\teurusd_minute.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7f079",
   "metadata": {},
   "source": [
    "## <font color='red'>Let's load the dataset for one-minute data prediction.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72556b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_hour = pd.read_csv(\"eurusd_hour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c28bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>BO</th>\n",
       "      <th>BH</th>\n",
       "      <th>BL</th>\n",
       "      <th>BC</th>\n",
       "      <th>BCh</th>\n",
       "      <th>AO</th>\n",
       "      <th>AH</th>\n",
       "      <th>AL</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>01:00</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>1.2848</td>\n",
       "      <td>1.2839</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>02:00</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.2845</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>03:00</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>04:00</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2849</td>\n",
       "      <td>1.2855</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time      BO      BH      BL      BC     BCh      AO      AH   \n",
       "0  2005-05-02  00:00  1.2852  1.2852  1.2840  1.2844 -0.0008  1.2854  1.2854  \\\n",
       "1  2005-05-02  01:00  1.2844  1.2848  1.2839  1.2842 -0.0002  1.2846  1.2850   \n",
       "2  2005-05-02  02:00  1.2843  1.2854  1.2841  1.2851  0.0008  1.2845  1.2856   \n",
       "3  2005-05-02  03:00  1.2851  1.2859  1.2850  1.2851  0.0000  1.2853  1.2861   \n",
       "4  2005-05-02  04:00  1.2852  1.2859  1.2849  1.2855  0.0003  1.2854  1.2861   \n",
       "\n",
       "       AL      AC     ACh  \n",
       "0  1.2842  1.2846 -0.0008  \n",
       "1  1.2841  1.2844 -0.0002  \n",
       "2  1.2843  1.2853  0.0008  \n",
       "3  1.2852  1.2853  0.0000  \n",
       "4  1.2851  1.2857  0.0003  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3968654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93084, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_hour.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9dbc3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2020-04-29', '2005-05-02')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(datasets_hour.Date), min(datasets_hour.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f0d1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_hour.BO.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcf96f",
   "metadata": {},
   "source": [
    "## <font color='red'>Given that time series data, such as forex market data, can exhibit seasonal patterns, I have decided to incorporate both date and hour information as training data. To encode these time units in a cyclical manner, I will use Periodicity encoding techniques, such as sine and cosine functions, to represent the cyclical patterns of date and hour information in a continuous and periodic manner.</font>\n",
    "\n",
    "    Periodicity encoding is a technique used in machine learning to represent time units, such as hours, days, months, or seasons, as periodic features using trigonometric functions, typically sine and cosine. This encoding allows the model to capture periodic patterns in the data more accurately, as it accounts for the cyclical nature of time units.\n",
    "\n",
    "    The basic idea behind periodicity encoding is to map time units onto a continuous scale that represents their cyclical patterns. For example, in a 24-hour time format, the hours repeat in a cyclical pattern from 0 to 23. By using sine and cosine functions, which have periodic properties with values ranging from -1 to 1, we can map the time units onto this continuous scale in a way that captures their cyclical patterns.\n",
    "\n",
    "    By encoding time units as periodic features, the model can learn to capture the cyclical patterns in the data more effectively. For example, in time series forecasting tasks, where the data exhibits periodic patterns such as daily or seasonal trends, periodicity encoding can help the model better understand and utilize these patterns in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aea5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_hour[\"month_sin\"] = datasets_hour.Date.apply(lambda x: np.sin(2 * np.pi * int(x.split(\"-\")[1]) / 12))\n",
    "datasets_hour[\"month_cos\"] = datasets_hour.Date.apply(lambda x: np.cos(2 * np.pi * int(x.split(\"-\")[1]) / 12))\n",
    "\n",
    "datasets_hour[\"date_sin\"] = datasets_hour.Date.apply(lambda x: np.sin(2 * np.pi * int(x.split(\"-\")[2]) / 31))\n",
    "datasets_hour[\"date_cos\"] = datasets_hour.Date.apply(lambda x: np.cos(2 * np.pi * int(x.split(\"-\")[2]) / 31))\n",
    "\n",
    "datasets_hour[\"hour_sin\"] = datasets_hour.Time.apply(lambda x: np.sin(2 * np.pi * int(x.split(\":\")[0]) / 12))\n",
    "datasets_hour[\"hour_cos\"] = datasets_hour.Time.apply(lambda x: np.cos(2 * np.pi * int(x.split(\":\")[0]) / 12)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2caaf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>BO</th>\n",
       "      <th>BH</th>\n",
       "      <th>BL</th>\n",
       "      <th>BC</th>\n",
       "      <th>BCh</th>\n",
       "      <th>AO</th>\n",
       "      <th>AH</th>\n",
       "      <th>AL</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACh</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>date_sin</th>\n",
       "      <th>date_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>01:00</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>1.2848</td>\n",
       "      <td>1.2839</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>02:00</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.2845</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>03:00</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-02</td>\n",
       "      <td>04:00</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2849</td>\n",
       "      <td>1.2855</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Time      BO      BH      BL      BC     BCh      AO      AH   \n",
       "0  2005-05-02  00:00  1.2852  1.2852  1.2840  1.2844 -0.0008  1.2854  1.2854  \\\n",
       "1  2005-05-02  01:00  1.2844  1.2848  1.2839  1.2842 -0.0002  1.2846  1.2850   \n",
       "2  2005-05-02  02:00  1.2843  1.2854  1.2841  1.2851  0.0008  1.2845  1.2856   \n",
       "3  2005-05-02  03:00  1.2851  1.2859  1.2850  1.2851  0.0000  1.2853  1.2861   \n",
       "4  2005-05-02  04:00  1.2852  1.2859  1.2849  1.2855  0.0003  1.2854  1.2861   \n",
       "\n",
       "       AL      AC     ACh  month_sin  month_cos  date_sin  date_cos  hour_sin   \n",
       "0  1.2842  1.2846 -0.0008        0.5  -0.866025  0.394356  0.918958  0.000000  \\\n",
       "1  1.2841  1.2844 -0.0002        0.5  -0.866025  0.394356  0.918958  0.500000   \n",
       "2  1.2843  1.2853  0.0008        0.5  -0.866025  0.394356  0.918958  0.866025   \n",
       "3  1.2852  1.2853  0.0000        0.5  -0.866025  0.394356  0.918958  1.000000   \n",
       "4  1.2851  1.2857  0.0003        0.5  -0.866025  0.394356  0.918958  0.866025   \n",
       "\n",
       "       hour_cos  \n",
       "0  1.000000e+00  \n",
       "1  8.660254e-01  \n",
       "2  5.000000e-01  \n",
       "3  6.123234e-17  \n",
       "4 -5.000000e-01  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e53291",
   "metadata": {},
   "source": [
    "## <font color='red'>I will exclude the \"Date\" and \"Time\" columns from the dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea59daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets_hour[datasets_hour.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63cd1e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BO</th>\n",
       "      <th>BH</th>\n",
       "      <th>BL</th>\n",
       "      <th>BC</th>\n",
       "      <th>BCh</th>\n",
       "      <th>AO</th>\n",
       "      <th>AH</th>\n",
       "      <th>AL</th>\n",
       "      <th>AC</th>\n",
       "      <th>ACh</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>date_sin</th>\n",
       "      <th>date_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2840</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2844</td>\n",
       "      <td>1.2848</td>\n",
       "      <td>1.2839</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>1.2846</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2844</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2841</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.2845</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2850</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2852</td>\n",
       "      <td>1.2859</td>\n",
       "      <td>1.2849</td>\n",
       "      <td>1.2855</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.2854</td>\n",
       "      <td>1.2861</td>\n",
       "      <td>1.2851</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BO      BH      BL      BC     BCh      AO      AH      AL      AC   \n",
       "0  1.2852  1.2852  1.2840  1.2844 -0.0008  1.2854  1.2854  1.2842  1.2846  \\\n",
       "1  1.2844  1.2848  1.2839  1.2842 -0.0002  1.2846  1.2850  1.2841  1.2844   \n",
       "2  1.2843  1.2854  1.2841  1.2851  0.0008  1.2845  1.2856  1.2843  1.2853   \n",
       "3  1.2851  1.2859  1.2850  1.2851  0.0000  1.2853  1.2861  1.2852  1.2853   \n",
       "4  1.2852  1.2859  1.2849  1.2855  0.0003  1.2854  1.2861  1.2851  1.2857   \n",
       "\n",
       "      ACh  month_sin  month_cos  date_sin  date_cos  hour_sin      hour_cos  \n",
       "0 -0.0008        0.5  -0.866025  0.394356  0.918958  0.000000  1.000000e+00  \n",
       "1 -0.0002        0.5  -0.866025  0.394356  0.918958  0.500000  8.660254e-01  \n",
       "2  0.0008        0.5  -0.866025  0.394356  0.918958  0.866025  5.000000e-01  \n",
       "3  0.0000        0.5  -0.866025  0.394356  0.918958  1.000000  6.123234e-17  \n",
       "4  0.0003        0.5  -0.866025  0.394356  0.918958  0.866025 -5.000000e-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90951538",
   "metadata": {},
   "source": [
    "## <font color='red'>Next, we will define the sequence and label for the prediction.</font>\n",
    "\n",
    "    In this approach, I will use a shortcut to map the dataset into a sequence array of IDs. This helps to minimize the time and memory required for formulating the dataset into a sequence from scratch, making the process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12021824",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 7 # total sequence\n",
    "TARGET_NEXT = 1 # next 1/2/3 hour(s)\n",
    "dt_length = datasets.shape[0] # total datasets\n",
    "TOTAL_SEQUENCE = dt_length // (SEQ + TARGET_NEXT)\n",
    "CHANNEL = datasets.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381ef92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,     5,     6,     7],\n",
       "       [    7,     8,     9, ...,    12,    13,    14],\n",
       "       [   14,    15,    16, ...,    19,    20,    21],\n",
       "       ...,\n",
       "       [11620, 11621, 11622, ..., 11625, 11626, 11627],\n",
       "       [11627, 11628, 11629, ..., 11632, 11633, 11634],\n",
       "       [11634, 11635, 11636, ..., 11639, 11640, 11641]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDS = np.expand_dims(np.arange(0, TOTAL_SEQUENCE, SEQ), axis=1) + np.arange(0, SEQ + TARGET_NEXT)\n",
    "IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca724762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,     4,     5,     6],\n",
       "       [    7,     8,     9, ...,    11,    12,    13],\n",
       "       [   14,    15,    16, ...,    18,    19,    20],\n",
       "       ...,\n",
       "       [11620, 11621, 11622, ..., 11624, 11625, 11626],\n",
       "       [11627, 11628, 11629, ..., 11631, 11632, 11633],\n",
       "       [11634, 11635, 11636, ..., 11638, 11639, 11640]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INP_IDS = IDS[:, :-TARGET_NEXT]\n",
    "INP_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923a60a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    7],\n",
       "       [   14],\n",
       "       [   21],\n",
       "       ...,\n",
       "       [11627],\n",
       "       [11634],\n",
       "       [11641]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBL_IDS = IDS[:, -1:]\n",
    "LBL_IDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221b2bc",
   "metadata": {},
   "source": [
    "## <font color='red'>Now we can use the ID sequence to map the dataset, separating it into input and label components.</font>\n",
    "    \n",
    "       In this scenario, I will attempt to predict two prices: the bid close price and ask close price. I will make the assumption that the predicted prices will be in the vicinity of the bid and ask close prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8bb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(datasets)[INP_IDS]\n",
    "Y = (np.array(datasets[[\"AC\", \"BC\"]])[LBL_IDS]) # predict labels\n",
    "Y = Y.reshape([Y.shape[0], Y.shape[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f7fa2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1663, 7, 16), (1663, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1702dba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.reshape([Y.shape[0], Y.shape[-1]]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67baa766",
   "metadata": {},
   "source": [
    "## <font color='red'>Now we can proceed to split our dataset into training and testing subsets.</font>\n",
    "\n",
    "    Since this is time series data, we won't shuffle the data during the splitting process. Instead, we'll split the data based on a given percentage, taking data from the last point in the dataset up to the specified percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfded8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9610321",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = X[:int(X.shape[0] * PERCENTAGE)], Y[:int(X.shape[0] * PERCENTAGE)]\n",
    "x_test, y_test = X[-int(X.shape[0] * PERCENTAGE):], Y[-int(X.shape[0] * PERCENTAGE):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c83b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:33:12.508478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22018 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866ea04",
   "metadata": {},
   "source": [
    "## <font color='red'>I will now proceed to construct our model for training.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b91a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(SEQ, CHANNEL))\n",
    "    x = tf.keras.layers.Conv1D(256, 3, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Conv1D(256, 3, activation='relu')(x) \n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=\"l2\")(x)\n",
    "    outputs = tf.keras.layers.Dense(Y.shape[1], activation=\"linear\")(x) \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(loss=\"mse\", \n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=[\"mse\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d10edc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 16)]           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5, 256)            12544     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3, 256)            196864    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 256)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,562\n",
      "Trainable params: 242,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f827d",
   "metadata": {},
   "source": [
    "## <font color='red'>We will define callbacks for updating the learning rate, implementing early stopping if the model does not show improvement, and saving the model whenever there is a decrease in the training loss.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc497ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor, patience, min_lr):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.wait = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # print('\\rlr_logs: ', logs, '\\r')\n",
    "        print(\"\\rwait: \", self.wait, \"\\r\")\n",
    "        print(\"\\rCurrent lr:\", tf.keras.backend.get_value(self.model.optimizer.lr), \"\\r\")\n",
    "        \n",
    "        current_val_loss = logs['val_loss'] \n",
    "        \n",
    "        if current_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            print(\"\\rself.wait >= self.patience:\", self.wait >= self.patience, \"\\r\")\n",
    "            if self.wait >= self.patience:\n",
    "                old_lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "                new_lr = old_lr * self.factor\n",
    "                \n",
    "                print(\"\\rnew_lr >= self.min_lr:\", new_lr >= self.min_lr, \"\\r\")\n",
    "                if new_lr >= self.min_lr:\n",
    "                    print(f'\\rEpoch {epoch+1}: Learning rate reduced to {new_lr} \\r')\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) \n",
    "                else:\n",
    "                    print(f'\\rEpoch {epoch+1}: Minimum learning rate reached\\r')\n",
    "                self.wait = 0\n",
    "                \n",
    "lr_callback = CustomLearningRateScheduler(factor=0.1, \n",
    "                                          patience=5,\n",
    "                                          min_lr=1e-7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65ae2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                               patience=4, # Number of epochs with no improvement after which training will be stopped.\n",
    "                                               start_from_epoch=1,\n",
    "                                               mode=\"min\") # training will stop when the quantity monitored has stopped decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc45a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpointCustom(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, model_path, save_best_only=False):\n",
    "        super(ModelCheckpointCustom, self).__init__()\n",
    "         \n",
    "        self.model_path = model_path\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_val_loss = float('inf') \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        print('\\rlogs: ', logs, '\\r')\n",
    "        \n",
    "        current_val_loss = 0 if logs['val_loss'] is None else logs['val_loss']\n",
    "        \n",
    "        print('\\rcurrent_val_loss: ', current_val_loss, '\\r')\n",
    "        print('\\rsave_best_only: ', self.save_best_only, '\\r')\n",
    "        print('\\rbest_val_loss: ', self.best_val_loss, '\\r')\n",
    "        print('\\rcurrent_val_loss < best_val_loss: ', current_val_loss < self.best_val_loss, '\\r') \n",
    "        \n",
    "        if self.save_best_only and current_val_loss < self.best_val_loss:\n",
    "            print('\\rSaving weights at (save_best_only=True): ', self.model_path, '\\r')\n",
    "            self.best_val_loss = current_val_loss \n",
    "            self.model.save_weights(self.model_path)\n",
    "            print(\"\\rModel has been saved!\")\n",
    "        else:\n",
    "            print('\\rSaving weights at (save_best_only=False): ', self.model_path, '\\r')\n",
    "            self.model.save_weights(self.model_path) \n",
    "            print(\"\\rModel has been saved!\")\n",
    "\n",
    "save_callbacks = ModelCheckpointCustom(model_path='checkpoint/save-model/', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae14953",
   "metadata": {},
   "source": [
    "## <font color='red'>Now, it is time to commence the training process of our model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e130e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "train = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).cache()\n",
    "test = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cafb6fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7, 16) (100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:33:16.839279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [332,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-10 17:33:16.853502: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x in train:\n",
    "    print(x[0].shape, x[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65e682b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:33:20.294874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-10 17:33:21.337446: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb67f11fdc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-10 17:33:21.337480: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-04-10 17:33:21.341291: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-10 17:33:21.462297: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs:  {'loss': 2.4645824432373047, 'mse': 0.7908599376678467, 'val_loss': 1.7107632160186768, 'val_mse': 0.1052289754152298} \n",
      "current_val_loss:  1.7107632160186768 \n",
      "save_best_only:  True \n",
      "best_val_loss:  inf \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 17:33:21.674334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [332,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 4s 140ms/step - loss: 2.4646 - mse: 0.7909 - val_loss: 1.7108 - val_mse: 0.1052\n",
      "Epoch 2/100\n",
      "logs:  {'loss': 1.773532748222351, 'mse': 0.19676128029823303, 'val_loss': 1.751091718673706, 'val_mse': 0.2411918044090271} \n",
      "current_val_loss:  1.751091718673706 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.7107632160186768 \n",
      "current_val_loss < best_val_loss:  False \n",
      "Saving weights at (save_best_only=False):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "self.wait >= self.patience: False \n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7735 - mse: 0.1968 - val_loss: 1.7511 - val_mse: 0.2412\n",
      "Epoch 3/100\n",
      "logs:  {'loss': 1.5793907642364502, 'mse': 0.09700287133455276, 'val_loss': 1.5053541660308838, 'val_mse': 0.08680351078510284} \n",
      "current_val_loss:  1.5053541660308838 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.7107632160186768 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  1 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.5794 - mse: 0.0970 - val_loss: 1.5054 - val_mse: 0.0868\n",
      "Epoch 4/100\n",
      "logs:  {'loss': 1.403863787651062, 'mse': 0.011685608886182308, 'val_loss': 1.3355591297149658, 'val_mse': 0.004388360772281885} \n",
      "current_val_loss:  1.3355591297149658 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.5053541660308838 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.4039 - mse: 0.0117 - val_loss: 1.3356 - val_mse: 0.0044\n",
      "Epoch 5/100\n",
      "logs:  {'loss': 1.346805453300476, 'mse': 0.040810227394104004, 'val_loss': 1.2590819597244263, 'val_mse': 0.011188531294465065} \n",
      "current_val_loss:  1.2590819597244263 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.3355591297149658 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.3468 - mse: 0.0408 - val_loss: 1.2591 - val_mse: 0.0112\n",
      "Epoch 6/100\n",
      "logs:  {'loss': 1.2293914556503296, 'mse': 0.005318025592714548, 'val_loss': 1.215027928352356, 'val_mse': 0.04581008478999138} \n",
      "current_val_loss:  1.215027928352356 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.2590819597244263 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2294 - mse: 0.0053 - val_loss: 1.2150 - val_mse: 0.0458\n",
      "Epoch 7/100\n",
      "logs:  {'loss': 1.1598050594329834, 'mse': 0.012972982600331306, 'val_loss': 1.1134319305419922, 'val_mse': 0.0181109756231308} \n",
      "current_val_loss:  1.1134319305419922 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.215027928352356 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.1598 - mse: 0.0130 - val_loss: 1.1134 - val_mse: 0.0181\n",
      "Epoch 8/100\n",
      "logs:  {'loss': 1.0773900747299194, 'mse': 0.0030598798766732216, 'val_loss': 1.029377818107605, 'val_mse': 0.0033249426633119583} \n",
      "current_val_loss:  1.029377818107605 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.1134319305419922 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0774 - mse: 0.0031 - val_loss: 1.0294 - val_mse: 0.0033\n",
      "Epoch 9/100\n",
      "logs:  {'loss': 1.0123178958892822, 'mse': 0.005923235323280096, 'val_loss': 0.9697349071502686, 'val_mse': 0.00848835427314043} \n",
      "current_val_loss:  0.9697349071502686 \n",
      "save_best_only:  True \n",
      "best_val_loss:  1.029377818107605 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0123 - mse: 0.0059 - val_loss: 0.9697 - val_mse: 0.0085\n",
      "Epoch 10/100\n",
      "logs:  {'loss': 0.9443934559822083, 'mse': 0.001480144215747714, 'val_loss': 0.91558837890625, 'val_mse': 0.014731436036527157} \n",
      "current_val_loss:  0.91558837890625 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.9697349071502686 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9444 - mse: 0.0015 - val_loss: 0.9156 - val_mse: 0.0147\n",
      "Epoch 11/100\n",
      "logs:  {'loss': 0.8866085410118103, 'mse': 0.0028003195766359568, 'val_loss': 0.8551672101020813, 'val_mse': 0.010482163168489933} \n",
      "current_val_loss:  0.8551672101020813 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.91558837890625 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8866 - mse: 0.0028 - val_loss: 0.8552 - val_mse: 0.0105\n",
      "Epoch 12/100\n",
      "logs:  {'loss': 0.8296746611595154, 'mse': 0.0008370747091248631, 'val_loss': 0.7986915707588196, 'val_mse': 0.0062061212956905365} \n",
      "current_val_loss:  0.7986915707588196 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.8551672101020813 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8297 - mse: 8.3707e-04 - val_loss: 0.7987 - val_mse: 0.0062\n",
      "Epoch 13/100\n",
      "logs:  {'loss': 0.7793130278587341, 'mse': 0.0015474127139896154, 'val_loss': 0.7497954368591309, 'val_mse': 0.0057712700217962265} \n",
      "current_val_loss:  0.7497954368591309 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.7986915707588196 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7793 - mse: 0.0015 - val_loss: 0.7498 - val_mse: 0.0058\n",
      "Epoch 14/100\n",
      "logs:  {'loss': 0.7309001684188843, 'mse': 0.0005369617138057947, 'val_loss': 0.7075956463813782, 'val_mse': 0.008547119796276093} \n",
      "current_val_loss:  0.7075956463813782 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.7497954368591309 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7309 - mse: 5.3696e-04 - val_loss: 0.7076 - val_mse: 0.0085\n",
      "Epoch 15/100\n",
      "logs:  {'loss': 0.6871048808097839, 'mse': 0.0007164205308072269, 'val_loss': 0.6650107502937317, 'val_mse': 0.007644219323992729} \n",
      "current_val_loss:  0.6650107502937317 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.7075956463813782 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.6871 - mse: 7.1642e-04 - val_loss: 0.6650 - val_mse: 0.0076\n",
      "Epoch 16/100\n",
      "logs:  {'loss': 0.6459832787513733, 'mse': 0.00035636540269479156, 'val_loss': 0.6233585476875305, 'val_mse': 0.004625663626939058} \n",
      "current_val_loss:  0.6233585476875305 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.6650107502937317 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6460 - mse: 3.5637e-04 - val_loss: 0.6234 - val_mse: 0.0046\n",
      "Epoch 17/100\n",
      "logs:  {'loss': 0.6083792448043823, 'mse': 0.0005249790265224874, 'val_loss': 0.5875293016433716, 'val_mse': 0.004611372947692871} \n",
      "current_val_loss:  0.5875293016433716 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.6233585476875305 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6084 - mse: 5.2498e-04 - val_loss: 0.5875 - val_mse: 0.0046\n",
      "Epoch 18/100\n",
      "logs:  {'loss': 0.5730856657028198, 'mse': 0.00025465257931500673, 'val_loss': 0.5558845400810242, 'val_mse': 0.006168575491756201} \n",
      "current_val_loss:  0.5558845400810242 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.5875293016433716 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5731 - mse: 2.5465e-04 - val_loss: 0.5559 - val_mse: 0.0062\n",
      "Epoch 19/100\n",
      "logs:  {'loss': 0.5406372547149658, 'mse': 0.000269637064775452, 'val_loss': 0.5234920978546143, 'val_mse': 0.0045397281646728516} \n",
      "current_val_loss:  0.5234920978546143 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.5558845400810242 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5406 - mse: 2.6964e-04 - val_loss: 0.5235 - val_mse: 0.0045\n",
      "Epoch 20/100\n",
      "logs:  {'loss': 0.5105341672897339, 'mse': 0.0002466181758791208, 'val_loss': 0.4939619302749634, 'val_mse': 0.003537039738148451} \n",
      "current_val_loss:  0.4939619302749634 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.5234920978546143 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5105 - mse: 2.4662e-04 - val_loss: 0.4940 - val_mse: 0.0035\n",
      "Epoch 21/100\n",
      "logs:  {'loss': 0.4826013147830963, 'mse': 0.00021419611584860831, 'val_loss': 0.4682891368865967, 'val_mse': 0.004329018760472536} \n",
      "current_val_loss:  0.4682891368865967 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.4939619302749634 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4826 - mse: 2.1420e-04 - val_loss: 0.4683 - val_mse: 0.0043\n",
      "Epoch 22/100\n",
      "logs:  {'loss': 0.4566726088523865, 'mse': 0.00017192996165249497, 'val_loss': 0.4433959722518921, 'val_mse': 0.003994374070316553} \n",
      "current_val_loss:  0.4433959722518921 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.4682891368865967 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4567 - mse: 1.7193e-04 - val_loss: 0.4434 - val_mse: 0.0040\n",
      "Epoch 23/100\n",
      "logs:  {'loss': 0.4326496720314026, 'mse': 0.00016642478294670582, 'val_loss': 0.4198104739189148, 'val_mse': 0.0032003927044570446} \n",
      "current_val_loss:  0.4198104739189148 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.4433959722518921 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4326 - mse: 1.6642e-04 - val_loss: 0.4198 - val_mse: 0.0032\n",
      "Epoch 24/100\n",
      "logs:  {'loss': 0.4103367328643799, 'mse': 0.0001589677412994206, 'val_loss': 0.39873018860816956, 'val_mse': 0.003304276382550597} \n",
      "current_val_loss:  0.39873018860816956 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.4198104739189148 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4103 - mse: 1.5897e-04 - val_loss: 0.3987 - val_mse: 0.0033\n",
      "Epoch 25/100\n",
      "logs:  {'loss': 0.389577716588974, 'mse': 0.00012940527813043445, 'val_loss': 0.3789312243461609, 'val_mse': 0.003194184275344014} \n",
      "current_val_loss:  0.3789312243461609 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.39873018860816956 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3896 - mse: 1.2941e-04 - val_loss: 0.3789 - val_mse: 0.0032\n",
      "Epoch 26/100\n",
      "logs:  {'loss': 0.37029778957366943, 'mse': 0.00012473456445150077, 'val_loss': 0.3601840138435364, 'val_mse': 0.0027752541936933994} \n",
      "current_val_loss:  0.3601840138435364 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.3789312243461609 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3703 - mse: 1.2473e-04 - val_loss: 0.3602 - val_mse: 0.0028\n",
      "Epoch 27/100\n",
      "logs:  {'loss': 0.35234928131103516, 'mse': 0.00011740535410353914, 'val_loss': 0.3429836332798004, 'val_mse': 0.002640519058331847} \n",
      "current_val_loss:  0.3429836332798004 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.3601840138435364 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3523 - mse: 1.1741e-04 - val_loss: 0.3430 - val_mse: 0.0026\n",
      "Epoch 28/100\n",
      "logs:  {'loss': 0.3356195092201233, 'mse': 0.00010233758803224191, 'val_loss': 0.3270045518875122, 'val_mse': 0.0025707341264933348} \n",
      "current_val_loss:  0.3270045518875122 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.3429836332798004 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3356 - mse: 1.0234e-04 - val_loss: 0.3270 - val_mse: 0.0026\n",
      "Epoch 29/100\n",
      "logs:  {'loss': 0.32002493739128113, 'mse': 9.486043563811108e-05, 'val_loss': 0.31193670630455017, 'val_mse': 0.0023518085945397615} \n",
      "current_val_loss:  0.31193670630455017 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.3270045518875122 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3200 - mse: 9.4860e-05 - val_loss: 0.3119 - val_mse: 0.0024\n",
      "Epoch 30/100\n",
      "logs:  {'loss': 0.30546998977661133, 'mse': 9.102275362238288e-05, 'val_loss': 0.29787373542785645, 'val_mse': 0.0021626853849738836} \n",
      "current_val_loss:  0.29787373542785645 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.31193670630455017 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3055 - mse: 9.1023e-05 - val_loss: 0.2979 - val_mse: 0.0022\n",
      "Epoch 31/100\n",
      "logs:  {'loss': 0.2918616533279419, 'mse': 8.226015779655427e-05, 'val_loss': 0.28484171628952026, 'val_mse': 0.0021060514263808727} \n",
      "current_val_loss:  0.28484171628952026 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.29787373542785645 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2919 - mse: 8.2260e-05 - val_loss: 0.2848 - val_mse: 0.0021\n",
      "Epoch 32/100\n",
      "logs:  {'loss': 0.27913036942481995, 'mse': 7.685121090617031e-05, 'val_loss': 0.2725151479244232, 'val_mse': 0.0019326162291690707} \n",
      "current_val_loss:  0.2725151479244232 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.28484171628952026 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2791 - mse: 7.6851e-05 - val_loss: 0.2725 - val_mse: 0.0019\n",
      "Epoch 33/100\n",
      "logs:  {'loss': 0.267204612493515, 'mse': 7.367708894889802e-05, 'val_loss': 0.2610165774822235, 'val_mse': 0.0018293238244950771} \n",
      "current_val_loss:  0.2610165774822235 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.2725151479244232 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2672 - mse: 7.3677e-05 - val_loss: 0.2610 - val_mse: 0.0018\n",
      "Epoch 34/100\n",
      "logs:  {'loss': 0.2560153603553772, 'mse': 6.92763933329843e-05, 'val_loss': 0.2502323091030121, 'val_mse': 0.0017483901465311646} \n",
      "current_val_loss:  0.2502323091030121 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.2610165774822235 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2560 - mse: 6.9276e-05 - val_loss: 0.2502 - val_mse: 0.0017\n",
      "Epoch 35/100\n",
      "logs:  {'loss': 0.24550335109233856, 'mse': 6.397804827429354e-05, 'val_loss': 0.24005326628684998, 'val_mse': 0.0016291046049445868} \n",
      "current_val_loss:  0.24005326628684998 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.2502323091030121 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2455 - mse: 6.3978e-05 - val_loss: 0.2401 - val_mse: 0.0016\n",
      "Epoch 36/100\n",
      "logs:  {'loss': 0.23561951518058777, 'mse': 6.267536082305014e-05, 'val_loss': 0.23048341274261475, 'val_mse': 0.0015331220347434282} \n",
      "current_val_loss:  0.23048341274261475 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.24005326628684998 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2356 - mse: 6.2675e-05 - val_loss: 0.2305 - val_mse: 0.0015\n",
      "Epoch 37/100\n",
      "logs:  {'loss': 0.22630569338798523, 'mse': 5.7588142226450145e-05, 'val_loss': 0.2214718759059906, 'val_mse': 0.00145356182474643} \n",
      "current_val_loss:  0.2214718759059906 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.23048341274261475 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2263 - mse: 5.7588e-05 - val_loss: 0.2215 - val_mse: 0.0015\n",
      "Epoch 38/100\n",
      "logs:  {'loss': 0.2175251543521881, 'mse': 5.649371450999752e-05, 'val_loss': 0.2129400372505188, 'val_mse': 0.0013535928446799517} \n",
      "current_val_loss:  0.2129400372505188 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.2214718759059906 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2175 - mse: 5.6494e-05 - val_loss: 0.2129 - val_mse: 0.0014\n",
      "Epoch 39/100\n",
      "logs:  {'loss': 0.20922799408435822, 'mse': 5.227255678619258e-05, 'val_loss': 0.20490844547748566, 'val_mse': 0.0012950419913977385} \n",
      "current_val_loss:  0.20490844547748566 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.2129400372505188 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2092 - mse: 5.2273e-05 - val_loss: 0.2049 - val_mse: 0.0013\n",
      "Epoch 40/100\n",
      "logs:  {'loss': 0.20138336718082428, 'mse': 5.047866943641566e-05, 'val_loss': 0.19727177917957306, 'val_mse': 0.0012056541163474321} \n",
      "current_val_loss:  0.19727177917957306 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.20490844547748566 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2014 - mse: 5.0479e-05 - val_loss: 0.1973 - val_mse: 0.0012\n",
      "Epoch 41/100\n",
      "logs:  {'loss': 0.19395248591899872, 'mse': 4.7583176637999713e-05, 'val_loss': 0.1900634765625, 'val_mse': 0.0011526728048920631} \n",
      "current_val_loss:  0.1900634765625 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.19727177917957306 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1940 - mse: 4.7583e-05 - val_loss: 0.1901 - val_mse: 0.0012\n",
      "Epoch 42/100\n",
      "logs:  {'loss': 0.186908558011055, 'mse': 4.7907771659083664e-05, 'val_loss': 0.18320634961128235, 'val_mse': 0.0010868454119190574} \n",
      "current_val_loss:  0.18320634961128235 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.1900634765625 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1869 - mse: 4.7908e-05 - val_loss: 0.1832 - val_mse: 0.0011\n",
      "Epoch 43/100\n",
      "logs:  {'loss': 0.18021509051322937, 'mse': 4.366506982478313e-05, 'val_loss': 0.17670108377933502, 'val_mse': 0.0010356998536735773} \n",
      "current_val_loss:  0.17670108377933502 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.18320634961128235 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1802 - mse: 4.3665e-05 - val_loss: 0.1767 - val_mse: 0.0010\n",
      "Epoch 44/100\n",
      "logs:  {'loss': 0.17385439574718475, 'mse': 4.245286982040852e-05, 'val_loss': 0.17048373818397522, 'val_mse': 0.0009602641803212464} \n",
      "current_val_loss:  0.17048373818397522 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.17670108377933502 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1739 - mse: 4.2453e-05 - val_loss: 0.1705 - val_mse: 9.6026e-04\n",
      "Epoch 45/100\n",
      "logs:  {'loss': 0.16779763996601105, 'mse': 3.931177707272582e-05, 'val_loss': 0.1645856499671936, 'val_mse': 0.0009142875787802041} \n",
      "current_val_loss:  0.1645856499671936 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.17048373818397522 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1678 - mse: 3.9312e-05 - val_loss: 0.1646 - val_mse: 9.1429e-04\n",
      "Epoch 46/100\n",
      "logs:  {'loss': 0.16202713549137115, 'mse': 3.8732963730581105e-05, 'val_loss': 0.15895257890224457, 'val_mse': 0.0008622026653029025} \n",
      "current_val_loss:  0.15895257890224457 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.1645856499671936 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1620 - mse: 3.8733e-05 - val_loss: 0.1590 - val_mse: 8.6220e-04\n",
      "Epoch 47/100\n",
      "logs:  {'loss': 0.1565217822790146, 'mse': 3.767300950130448e-05, 'val_loss': 0.15359213948249817, 'val_mse': 0.0008301305933855474} \n",
      "current_val_loss:  0.15359213948249817 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.15895257890224457 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1565 - mse: 3.7673e-05 - val_loss: 0.1536 - val_mse: 8.3013e-04\n",
      "Epoch 48/100\n",
      "logs:  {'loss': 0.1512613594532013, 'mse': 3.553729402483441e-05, 'val_loss': 0.14844566583633423, 'val_mse': 0.000778250687289983} \n",
      "current_val_loss:  0.14844566583633423 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.15359213948249817 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1513 - mse: 3.5537e-05 - val_loss: 0.1484 - val_mse: 7.7825e-04\n",
      "Epoch 49/100\n",
      "logs:  {'loss': 0.14623384177684784, 'mse': 3.461808955762535e-05, 'val_loss': 0.14354398846626282, 'val_mse': 0.0007500648498535156} \n",
      "current_val_loss:  0.14354398846626282 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.14844566583633423 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1462 - mse: 3.4618e-05 - val_loss: 0.1435 - val_mse: 7.5006e-04\n",
      "Epoch 50/100\n",
      "logs:  {'loss': 0.1414211094379425, 'mse': 3.296208524261601e-05, 'val_loss': 0.1388343721628189, 'val_mse': 0.0007072448497638106} \n",
      "current_val_loss:  0.1388343721628189 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.14354398846626282 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1414 - mse: 3.2962e-05 - val_loss: 0.1388 - val_mse: 7.0724e-04\n",
      "Epoch 51/100\n",
      "logs:  {'loss': 0.13681171834468842, 'mse': 3.159046173095703e-05, 'val_loss': 0.13432765007019043, 'val_mse': 0.000673856760840863} \n",
      "current_val_loss:  0.13432765007019043 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.1388343721628189 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1368 - mse: 3.1590e-05 - val_loss: 0.1343 - val_mse: 6.7386e-04\n",
      "Epoch 52/100\n",
      "logs:  {'loss': 0.13239242136478424, 'mse': 3.0513268939103e-05, 'val_loss': 0.13001315295696259, 'val_mse': 0.0006499385926872492} \n",
      "current_val_loss:  0.13001315295696259 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.13432765007019043 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1324 - mse: 3.0513e-05 - val_loss: 0.1300 - val_mse: 6.4994e-04\n",
      "Epoch 53/100\n",
      "logs:  {'loss': 0.1281525045633316, 'mse': 2.9911478122812696e-05, 'val_loss': 0.12585796415805817, 'val_mse': 0.0006140851764939725} \n",
      "current_val_loss:  0.12585796415805817 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.13001315295696259 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1282 - mse: 2.9911e-05 - val_loss: 0.1259 - val_mse: 6.1409e-04\n",
      "Epoch 54/100\n",
      "logs:  {'loss': 0.12408102303743362, 'mse': 2.856283390428871e-05, 'val_loss': 0.1218886449933052, 'val_mse': 0.0006024837493896484} \n",
      "current_val_loss:  0.1218886449933052 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.12585796415805817 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1241 - mse: 2.8563e-05 - val_loss: 0.1219 - val_mse: 6.0248e-04\n",
      "Epoch 55/100\n",
      "logs:  {'loss': 0.12016891688108444, 'mse': 2.7820287868962623e-05, 'val_loss': 0.11805619299411774, 'val_mse': 0.0005743646761402488} \n",
      "current_val_loss:  0.11805619299411774 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.1218886449933052 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1202 - mse: 2.7820e-05 - val_loss: 0.1181 - val_mse: 5.7436e-04\n",
      "Epoch 56/100\n",
      "logs:  {'loss': 0.11640754342079163, 'mse': 2.6925501515506767e-05, 'val_loss': 0.11438974738121033, 'val_mse': 0.0005672741099260747} \n",
      "current_val_loss:  0.11438974738121033 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.11805619299411774 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1164 - mse: 2.6926e-05 - val_loss: 0.1144 - val_mse: 5.6727e-04\n",
      "Epoch 57/100\n",
      "logs:  {'loss': 0.11278889328241348, 'mse': 2.6546329536358826e-05, 'val_loss': 0.11083987355232239, 'val_mse': 0.0005396890919655561} \n",
      "current_val_loss:  0.11083987355232239 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.11438974738121033 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1128 - mse: 2.6546e-05 - val_loss: 0.1108 - val_mse: 5.3969e-04\n",
      "Epoch 58/100\n",
      "logs:  {'loss': 0.10930491983890533, 'mse': 2.5532332074362785e-05, 'val_loss': 0.10743322223424911, 'val_mse': 0.0005256128497421741} \n",
      "current_val_loss:  0.10743322223424911 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.11083987355232239 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1093 - mse: 2.5532e-05 - val_loss: 0.1074 - val_mse: 5.2561e-04\n",
      "Epoch 59/100\n",
      "logs:  {'loss': 0.1059492975473404, 'mse': 2.4848674001987092e-05, 'val_loss': 0.1041402593255043, 'val_mse': 0.0005011558532714844} \n",
      "current_val_loss:  0.1041402593255043 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.10743322223424911 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1059 - mse: 2.4849e-05 - val_loss: 0.1041 - val_mse: 5.0116e-04\n",
      "Epoch 60/100\n",
      "logs:  {'loss': 0.10271637886762619, 'mse': 2.4582966943853535e-05, 'val_loss': 0.10097957402467728, 'val_mse': 0.0004907417460344732} \n",
      "current_val_loss:  0.10097957402467728 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.1041402593255043 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1027 - mse: 2.4583e-05 - val_loss: 0.1010 - val_mse: 4.9074e-04\n",
      "Epoch 61/100\n",
      "logs:  {'loss': 0.09959939867258072, 'mse': 2.4400562324444763e-05, 'val_loss': 0.09793531149625778, 'val_mse': 0.00048482895363122225} \n",
      "current_val_loss:  0.09793531149625778 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.10097957402467728 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0996 - mse: 2.4401e-05 - val_loss: 0.0979 - val_mse: 4.8483e-04\n",
      "Epoch 62/100\n",
      "logs:  {'loss': 0.09659277647733688, 'mse': 2.4073095119092613e-05, 'val_loss': 0.09497692435979843, 'val_mse': 0.0004578590451274067} \n",
      "current_val_loss:  0.09497692435979843 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.09793531149625778 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0966 - mse: 2.4073e-05 - val_loss: 0.0950 - val_mse: 4.5786e-04\n",
      "Epoch 63/100\n",
      "logs:  {'loss': 0.09369189292192459, 'mse': 2.359625796088949e-05, 'val_loss': 0.0921231210231781, 'val_mse': 0.00043298720265738666} \n",
      "current_val_loss:  0.0921231210231781 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.09497692435979843 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0937 - mse: 2.3596e-05 - val_loss: 0.0921 - val_mse: 4.3299e-04\n",
      "Epoch 64/100\n",
      "logs:  {'loss': 0.0908912718296051, 'mse': 2.2523374354932457e-05, 'val_loss': 0.08938837051391602, 'val_mse': 0.0004301547887735069} \n",
      "current_val_loss:  0.08938837051391602 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.0921231210231781 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0909 - mse: 2.2523e-05 - val_loss: 0.0894 - val_mse: 4.3015e-04\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs:  {'loss': 0.08818794786930084, 'mse': 2.2740248823538423e-05, 'val_loss': 0.08675126731395721, 'val_mse': 0.00043171882862225175} \n",
      "current_val_loss:  0.08675126731395721 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.08938837051391602 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0882 - mse: 2.2740e-05 - val_loss: 0.0868 - val_mse: 4.3172e-04\n",
      "Epoch 66/100\n",
      "logs:  {'loss': 0.08557727187871933, 'mse': 2.3482793039875105e-05, 'val_loss': 0.0841749757528305, 'val_mse': 0.0004036426544189453} \n",
      "current_val_loss:  0.0841749757528305 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.08675126731395721 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0856 - mse: 2.3483e-05 - val_loss: 0.0842 - val_mse: 4.0364e-04\n",
      "Epoch 67/100\n",
      "logs:  {'loss': 0.083053357899189, 'mse': 2.238693014078308e-05, 'val_loss': 0.08168421685695648, 'val_mse': 0.00037517547025345266} \n",
      "current_val_loss:  0.08168421685695648 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.0841749757528305 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0831 - mse: 2.2387e-05 - val_loss: 0.0817 - val_mse: 3.7518e-04\n",
      "Epoch 68/100\n",
      "logs:  {'loss': 0.08061533421278, 'mse': 2.2267720851232298e-05, 'val_loss': 0.0793135017156601, 'val_mse': 0.00038614272489212453} \n",
      "current_val_loss:  0.0793135017156601 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.08168421685695648 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0806 - mse: 2.2268e-05 - val_loss: 0.0793 - val_mse: 3.8614e-04\n",
      "Epoch 69/100\n",
      "logs:  {'loss': 0.07825793325901031, 'mse': 2.206520912295673e-05, 'val_loss': 0.07702859491109848, 'val_mse': 0.00040413381066173315} \n",
      "current_val_loss:  0.07702859491109848 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.0793135017156601 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0783 - mse: 2.2065e-05 - val_loss: 0.0770 - val_mse: 4.0413e-04\n",
      "Epoch 70/100\n",
      "logs:  {'loss': 0.07598066329956055, 'mse': 2.4588711312389933e-05, 'val_loss': 0.07477639615535736, 'val_mse': 0.0003774452197831124} \n",
      "current_val_loss:  0.07477639615535736 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.07702859491109848 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0760 - mse: 2.4589e-05 - val_loss: 0.0748 - val_mse: 3.7745e-04\n",
      "Epoch 71/100\n",
      "logs:  {'loss': 0.07377585023641586, 'mse': 2.4065913748927414e-05, 'val_loss': 0.07254673540592194, 'val_mse': 0.00029879092471674085} \n",
      "current_val_loss:  0.07254673540592194 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.07477639615535736 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0738 - mse: 2.4066e-05 - val_loss: 0.0725 - val_mse: 2.9879e-04\n",
      "Epoch 72/100\n",
      "logs:  {'loss': 0.07164978235960007, 'mse': 2.98856248264201e-05, 'val_loss': 0.07046874612569809, 'val_mse': 0.00030595780117437243} \n",
      "current_val_loss:  0.07046874612569809 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.07254673540592194 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0716 - mse: 2.9886e-05 - val_loss: 0.0705 - val_mse: 3.0596e-04\n",
      "Epoch 73/100\n",
      "logs:  {'loss': 0.0695820227265358, 'mse': 2.5543822630424984e-05, 'val_loss': 0.06857546418905258, 'val_mse': 0.00043393136002123356} \n",
      "current_val_loss:  0.06857546418905258 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.07046874612569809 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0696 - mse: 2.5544e-05 - val_loss: 0.0686 - val_mse: 4.3393e-04\n",
      "Epoch 74/100\n",
      "logs:  {'loss': 0.06761090457439423, 'mse': 5.2628747653216124e-05, 'val_loss': 0.066652812063694, 'val_mse': 0.0004623508430086076} \n",
      "current_val_loss:  0.066652812063694 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.06857546418905258 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0676 - mse: 5.2629e-05 - val_loss: 0.0667 - val_mse: 4.6235e-04\n",
      "Epoch 75/100\n",
      "logs:  {'loss': 0.06567732989788055, 'mse': 5.2999301260570064e-05, 'val_loss': 0.06454309076070786, 'val_mse': 0.0002329921699129045} \n",
      "current_val_loss:  0.06454309076070786 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.066652812063694 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0657 - mse: 5.2999e-05 - val_loss: 0.0645 - val_mse: 2.3299e-04\n",
      "Epoch 76/100\n",
      "logs:  {'loss': 0.063871368765831, 'mse': 0.00011625347542576492, 'val_loss': 0.06269878894090652, 'val_mse': 0.00021517754066735506} \n",
      "current_val_loss:  0.06269878894090652 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.06454309076070786 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0639 - mse: 1.1625e-04 - val_loss: 0.0627 - val_mse: 2.1518e-04\n",
      "Epoch 77/100\n",
      "logs:  {'loss': 0.06208552420139313, 'mse': 0.00013817218132317066, 'val_loss': 0.06127699837088585, 'val_mse': 0.0005789184360764921} \n",
      "current_val_loss:  0.06127699837088585 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.06269878894090652 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0621 - mse: 1.3817e-04 - val_loss: 0.0613 - val_mse: 5.7892e-04\n",
      "Epoch 78/100\n",
      "logs:  {'loss': 0.06036834791302681, 'mse': 0.00017735183064360172, 'val_loss': 0.059611085802316666, 'val_mse': 0.0006291389581747353} \n",
      "current_val_loss:  0.059611085802316666 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.06127699837088585 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0604 - mse: 1.7735e-04 - val_loss: 0.0596 - val_mse: 6.2914e-04\n",
      "Epoch 79/100\n",
      "logs:  {'loss': 0.05869770050048828, 'mse': 0.0002104417362716049, 'val_loss': 0.05750742927193642, 'val_mse': 0.00016669750039000064} \n",
      "current_val_loss:  0.05750742927193642 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.059611085802316666 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0587 - mse: 2.1044e-04 - val_loss: 0.0575 - val_mse: 1.6670e-04\n",
      "Epoch 80/100\n",
      "logs:  {'loss': 0.05699079483747482, 'mse': 0.00014035098138265312, 'val_loss': 0.05609947070479393, 'val_mse': 0.00037098408211022615} \n",
      "current_val_loss:  0.05609947070479393 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.05750742927193642 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0570 - mse: 1.4035e-04 - val_loss: 0.0561 - val_mse: 3.7098e-04\n",
      "Epoch 81/100\n",
      "logs:  {'loss': 0.05534979701042175, 'mse': 8.794054883765057e-05, 'val_loss': 0.054766178131103516, 'val_mse': 0.000603795051574707} \n",
      "current_val_loss:  0.054766178131103516 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.05609947070479393 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0553 - mse: 8.7941e-05 - val_loss: 0.0548 - val_mse: 6.0380e-04\n",
      "Epoch 82/100\n",
      "logs:  {'loss': 0.053754374384880066, 'mse': 4.264963718014769e-05, 'val_loss': 0.052918337285518646, 'val_mse': 0.0002596855047158897} \n",
      "current_val_loss:  0.052918337285518646 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.054766178131103516 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0538 - mse: 4.2650e-05 - val_loss: 0.0529 - val_mse: 2.5969e-04\n",
      "Epoch 83/100\n",
      "logs:  {'loss': 0.052241526544094086, 'mse': 2.461743679305073e-05, 'val_loss': 0.05155044421553612, 'val_mse': 0.00035844327067025006} \n",
      "current_val_loss:  0.05155044421553612 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.052918337285518646 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0522 - mse: 2.4617e-05 - val_loss: 0.0516 - val_mse: 3.5844e-04\n",
      "Epoch 84/100\n",
      "logs:  {'loss': 0.050794485956430435, 'mse': 2.7173973649041727e-05, 'val_loss': 0.05017050728201866, 'val_mse': 0.00039868353633210063} \n",
      "current_val_loss:  0.05017050728201866 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.05155044421553612 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0508 - mse: 2.7174e-05 - val_loss: 0.0502 - val_mse: 3.9868e-04\n",
      "Epoch 85/100\n",
      "logs:  {'loss': 0.04938531294465065, 'mse': 2.6247587811667472e-05, 'val_loss': 0.048670005053281784, 'val_mse': 0.0002705478691495955} \n",
      "current_val_loss:  0.048670005053281784 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.05017050728201866 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0494 - mse: 2.6248e-05 - val_loss: 0.0487 - val_mse: 2.7055e-04\n",
      "Epoch 86/100\n",
      "logs:  {'loss': 0.04802402853965759, 'mse': 2.7428190151113085e-05, 'val_loss': 0.047365766018629074, 'val_mse': 0.0003025770129170269} \n",
      "current_val_loss:  0.047365766018629074 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.048670005053281784 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0480 - mse: 2.7428e-05 - val_loss: 0.0474 - val_mse: 3.0258e-04\n",
      "Epoch 87/100\n",
      "logs:  {'loss': 0.04669903218746185, 'mse': 2.4044369638431817e-05, 'val_loss': 0.04614724963903427, 'val_mse': 0.00038173675420694053} \n",
      "current_val_loss:  0.04614724963903427 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.047365766018629074 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0467 - mse: 2.4044e-05 - val_loss: 0.0461 - val_mse: 3.8174e-04\n",
      "Epoch 88/100\n",
      "logs:  {'loss': 0.04541858285665512, 'mse': 2.7867685275850818e-05, 'val_loss': 0.04481266811490059, 'val_mse': 0.0003006696642842144} \n",
      "current_val_loss:  0.04481266811490059 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.04614724963903427 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0454 - mse: 2.7868e-05 - val_loss: 0.0448 - val_mse: 3.0067e-04\n",
      "Epoch 89/100\n",
      "logs:  {'loss': 0.04416849464178085, 'mse': 2.230793506896589e-05, 'val_loss': 0.04352346435189247, 'val_mse': 0.00022644043201580644} \n",
      "current_val_loss:  0.04352346435189247 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.04481266811490059 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0442 - mse: 2.2308e-05 - val_loss: 0.0435 - val_mse: 2.2644e-04\n",
      "Epoch 90/100\n",
      "logs:  {'loss': 0.04296319931745529, 'mse': 2.251044861623086e-05, 'val_loss': 0.04237314686179161, 'val_mse': 0.0002586317132227123} \n",
      "current_val_loss:  0.04237314686179161 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.04352346435189247 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0430 - mse: 2.2510e-05 - val_loss: 0.0424 - val_mse: 2.5863e-04\n",
      "Epoch 91/100\n",
      "logs:  {'loss': 0.04179096594452858, 'mse': 2.0611716536222957e-05, 'val_loss': 0.041281476616859436, 'val_mse': 0.00031616687192581594} \n",
      "current_val_loss:  0.041281476616859436 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.04237314686179161 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0418 - mse: 2.0612e-05 - val_loss: 0.0413 - val_mse: 3.1617e-04\n",
      "Epoch 92/100\n",
      "logs:  {'loss': 0.04065733775496483, 'mse': 2.4011336790863425e-05, 'val_loss': 0.040137942880392075, 'val_mse': 0.0002841567911673337} \n",
      "current_val_loss:  0.040137942880392075 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.041281476616859436 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0407 - mse: 2.4011e-05 - val_loss: 0.0401 - val_mse: 2.8416e-04\n",
      "Epoch 93/100\n",
      "logs:  {'loss': 0.039552219212055206, 'mse': 2.205228156526573e-05, 'val_loss': 0.038974277675151825, 'val_mse': 0.0001967334683286026} \n",
      "current_val_loss:  0.038974277675151825 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.040137942880392075 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0396 - mse: 2.2052e-05 - val_loss: 0.0390 - val_mse: 1.9673e-04\n",
      "Epoch 94/100\n",
      "logs:  {'loss': 0.038485217839479446, 'mse': 2.408314867352601e-05, 'val_loss': 0.0379101000726223, 'val_mse': 0.0001804780913516879} \n",
      "current_val_loss:  0.0379101000726223 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.038974277675151825 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0385 - mse: 2.4083e-05 - val_loss: 0.0379 - val_mse: 1.8048e-04\n",
      "Epoch 95/100\n",
      "logs:  {'loss': 0.03745577856898308, 'mse': 3.382814975338988e-05, 'val_loss': 0.03689871355891228, 'val_mse': 0.0001870202977443114} \n",
      "current_val_loss:  0.03689871355891228 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.0379101000726223 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0375 - mse: 3.3828e-05 - val_loss: 0.0369 - val_mse: 1.8702e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs:  {'loss': 0.036444973200559616, 'mse': 3.099154127994552e-05, 'val_loss': 0.035958100110292435, 'val_mse': 0.00023708344087935984} \n",
      "current_val_loss:  0.035958100110292435 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.03689871355891228 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0364 - mse: 3.0992e-05 - val_loss: 0.0360 - val_mse: 2.3708e-04\n",
      "Epoch 97/100\n",
      "logs:  {'loss': 0.035526081919670105, 'mse': 8.90479059307836e-05, 'val_loss': 0.035445310175418854, 'val_mse': 0.0006884622853249311} \n",
      "current_val_loss:  0.035445310175418854 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.035958100110292435 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0355 - mse: 8.9048e-05 - val_loss: 0.0354 - val_mse: 6.8846e-04\n",
      "Epoch 98/100\n",
      "logs:  {'loss': 0.03475109860301018, 'mse': 0.0002641247119754553, 'val_loss': 0.03439217433333397, 'val_mse': 0.0005604076432064176} \n",
      "current_val_loss:  0.03439217433333397 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.035445310175418854 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0348 - mse: 2.6412e-04 - val_loss: 0.0344 - val_mse: 5.6041e-04\n",
      "Epoch 99/100\n",
      "logs:  {'loss': 0.03375678136944771, 'mse': 0.00019387883367016912, 'val_loss': 0.03315281867980957, 'val_mse': 0.00019627570873126388} \n",
      "current_val_loss:  0.03315281867980957 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.03439217433333397 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0338 - mse: 1.9388e-04 - val_loss: 0.0332 - val_mse: 1.9628e-04\n",
      "Epoch 100/100\n",
      "logs:  {'loss': 0.033644743263721466, 'mse': 0.0009702027309685946, 'val_loss': 0.03231458365917206, 'val_mse': 0.00023204326862469316} \n",
      "current_val_loss:  0.03231458365917206 \n",
      "save_best_only:  True \n",
      "best_val_loss:  0.03315281867980957 \n",
      "current_val_loss < best_val_loss:  True \n",
      "Saving weights at (save_best_only=True):  checkpoint/save-model/ \n",
      "Model has been saved!\n",
      "wait:  0 \n",
      "Current lr: 0.001 \n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0336 - mse: 9.7020e-04 - val_loss: 0.0323 - val_mse: 2.3204e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=100, validation_data=test, validation_steps=len(test) * 0.25, callbacks=[save_callbacks, es_callback, lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "858f34c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afbe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
